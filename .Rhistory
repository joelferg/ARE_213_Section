lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*4)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=5
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(100)
Y_oos = sin(X_oos*6)/X_oos + runif(100,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[1,1]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(100)
Y_oos = sin(X_oos*6)/X_oos + runif(100,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[1,1]=10
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(100)
Y_oos = sin(X_oos*6)/X_oos + runif(100,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
oos_df = data.frame("Y"=Y_oos,
"X"=X_oos,
"Y_ols"=Y_hat_ols,
"Y_ridge"=Y_hat_right)
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
oos_df = data.frame("Y"=Y_oos,
"X"=X_oos,
"Y_ols"=Y_hat_ols,
"Y_ridge"=Y_hat_ridge)
ggplot(data=oos_df)+
geom_point(aes(x=X,y=Y))+
geom_point(aes(x=X,y=Y_ols),color="blue")+
geom_point(aes(x=X,y=Y_ridge),color="orange")
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 10000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
oos_df = data.frame("Y"=Y_oos,
"X"=X_oos,
"Y_ols"=Y_hat_ols,
"Y_ridge"=Y_hat_ridge)
ggplot(data=oos_df)+
geom_point(aes(x=X,y=Y))+
geom_point(aes(x=X,y=Y_ols),color="blue")+
geom_point(aes(x=X,y=Y_ridge),color="orange")
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 100000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
lambda[2,2]=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
oos_df = data.frame("Y"=Y_oos,
"X"=X_oos,
"Y_ols"=Y_hat_ols,
"Y_ridge"=Y_hat_ridge)
ggplot(data=oos_df)+
geom_point(aes(x=X,y=Y))+
geom_point(aes(x=X,y=Y_ols),color="blue")+
geom_point(aes(x=X,y=Y_ridge),color="orange")
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 100000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
diag(lambda)=100
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y-Y_hat_ols)^2)
MSE_ridge = mean((Y-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
diag(lambda)=100
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y_oos-Y_hat_ols)^2)
MSE_ridge = mean((Y_oos-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
# Choose N
N = 1000
# Choose N Xs in [0,1]
X = runif(N)
# Now CEF is going to be nonlinear
Y = sin(X*6)/X + runif(N,-0.2,0.2)
# Run ols
X_ols = cbind(matrix(1,nrow=N,ncol=1),X)
ab_hat = solve(t(X_ols)%*%X_ols)%*%(t(X_ols)%*%Y)
# Now lets try a different linear predictor, e.g. ridge regression
lambda = matrix(0,nrow=2,ncol=2)
diag(lambda)=10
ridge_ab = solve(t(X_ols)%*%X_ols+lambda)%*%(t(X_ols)%*%Y)
df = data.frame("Y"=Y,
"X"=X)
ggplot(data=df)+
geom_point(aes(x=X,y=Y))+
geom_abline(intercept=ab_hat[1],slope=ab_hat[2],color="blue")+
geom_abline(intercept=ridge_ab[1],slope=ridge_ab[2],color="orange")
# Let's calculate the MSE on a new sample
X_oos = runif(N)
Y_oos = sin(X_oos*6)/X_oos + runif(N,-0.2,0.2)
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_oos
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_oos
MSE_ols = mean((Y_oos-Y_hat_ols)^2)
MSE_ridge = mean((Y_oos-Y_hat_ridge)^2)
print(paste("OLS out of sample MSE:",round(MSE_ols,2)))
print(paste("Ridge out of sample MSE:",round(MSE_ridge,2)))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
set.seed(82922)
X_line = runif(100000)
Y_line = sin(X_line*6)/X_line # No error for CEF
Y_hat_ols = ab_hat[1]+ab_hat[2]*X_line
Y_hat_ridge = ridge_ab[1] + ridge_ab[2]*X_line
cef_df = data.frame("Y"=Y_line,
"X"=X_line,
"Y_ols"=Y_hat_ols,
"Y_ridge"=Y_hat_ridge)
ggplot(data=cef_df)+
geom_line(aes(x=X,y=Y))+
geom_line(aes(x=X,y=Y_ols),color="blue")+
geom_line(aes(x=X,y=Y_ridge),color="orange")
MSE_ols = mean((Y_line-Y_hat_ols)^2)
MSE_ridge = mean((Y_line-Y_hat_ridge)^2)
print(paste("OLS MSE:",round(MSE_ols,2)))
print(paste("Ridge MSE:",round(MSE_ridge,2)))
